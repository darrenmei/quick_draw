{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "#import torchvision.datasets as dset\n",
    "#import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from basic import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# For this cell used same code from PyTorch notebook in assignment 2 of Stanford's CS231n Spring 2018 offering\n",
    "preprocessData = False # To preprocess data set this to True\n",
    "USE_GPU = False\n",
    "dtype = torch.float32\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.float32\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 1\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next two cells, code belongs to [1]. Minor changes made to accomodate to our use \n",
    "# (Using PyTorch instead of Keras/tensorflow)\n",
    "IMG_WIDTH = 28\n",
    "IMG_HEIGHT = 28\n",
    "IMG_CHANNELS = 1\n",
    "PATH = './'\n",
    "epsilon = 1e-12 #For numerical stability\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 1\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (364984, 1, 28, 28)\n",
      "Y_train shape: (364984,)\n",
      "X_dev shape: (121661, 1, 28, 28)\n",
      "Y_dev shape: (121661,)\n"
     ]
    }
   ],
   "source": [
    "trainCSV = \"./train_npy.csv\"\n",
    "trainDF = pd.read_csv(trainCSV, header = 0)\n",
    "trainDF = trainDF.values\n",
    "X_t = trainDF[:, 0:-5]\n",
    "X_train = np.zeros((len(X_t), 1, 28, 28), dtype= np.float32)\n",
    "for i, row in enumerate(X_t):\n",
    "    X_train[i] = np.reshape(X_t[i, :], (1, 28, 28))\n",
    "# want shape [samples, 1, 28, 28]\n",
    "Y_t = trainDF[:, -5:]   #label x sample\n",
    "Y_train = np.zeros((Y_t.shape[0]))\n",
    "# Pytorch needs indices\n",
    "for i, row in enumerate(Y_t):\n",
    "    Y_train[i] = np.argmax(row)\n",
    "devCSV = \"./dev_npy.csv\"\n",
    "devDF = pd.read_csv(devCSV, header = 0)\n",
    "devDF = devDF.values\n",
    "X_d = devDF[:, 0:-5]\n",
    "X_dev = np.zeros((len(X_d), 1, 28, 28), dtype= np.float32)\n",
    "for i, row in enumerate(X_d):\n",
    "    X_dev[i] = np.reshape(X_d[i, :], (1, 28, 28))\n",
    "Y_d = devDF[:, -5:]   #label x sample\n",
    "Y_dev = np.zeros((Y_d.shape[0]))\n",
    "for i, row in enumerate(Y_d):\n",
    "    Y_train[i] = np.argmax(row)\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "print (\"Y_dev shape: \" + str(Y_dev.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showVisualComparisons(X, y, ex):\n",
    "    plt.imshow(np.uint8(np.reshape(X[ex, :], (28, 28))))\n",
    "    plt.show()\n",
    "    print(Y_train[:, ex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel(model, x_train, y_train, optimizer, epochs = 1, mini_batch_size = 64, noVal = False):\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    T = 0\n",
    "    num_batches = int(len(x_train)/mini_batch_size)\n",
    "    num_remaining = len(x_train) - num_batches * mini_batch_size\n",
    "    loss_history = []\n",
    "    correct = 0\n",
    "    for e in range(epochs):\n",
    "        for t in range(num_batches):\n",
    "            rand_indices = np.random.choice(len(x_train), mini_batch_size)\n",
    "            x = torch.from_numpy(x_train[rand_indices, :, :, :])\n",
    "            y = torch.from_numpy(y_train[rand_indices])\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            print('y shape: ', y.shape)\n",
    "\n",
    "            preds = model(x)\n",
    "            _, predicted = torch.max(preds.data, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            \n",
    "            loss = F.cross_entropy(preds, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if T % print_every == 0:\n",
    "                currLoss = loss.item()\n",
    "                loss_history.append(currLoss)\n",
    "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, t, currLoss))\n",
    "            if (num_remaining <= 0 and t == (num_batches -1)):\n",
    "                perf = calculatePerformance(x_train, y_train, model)\n",
    "                print('Train performance at epoch %d is %.4f' % (e, perf))\n",
    "                if (noVal == False):\n",
    "                    perf = calculatePerformance(X_val, Y_val, model)\n",
    "                    print('Val performance at epoch %d is %.4f' % (e, perf))\n",
    "            T +=1\n",
    "        if num_remaining > 0:\n",
    "            rand_indices = np.random.choice(len(x_train), num_remaining)\n",
    "\n",
    "            x = torch.from_numpy(x_train[rand_indices, :, :, :])\n",
    "            y = torch.from_numpy(y_train[rand_indices])\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            \n",
    "\n",
    "\n",
    "            preds = model(x)\n",
    "            _, predicted = torch.max(preds.data, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            #values, indices = torch.max(preds, 1)\n",
    "            loss = F.cross_entropy(preds, y)\n",
    "            #loss(preds, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            if T % print_every == 0:\n",
    "                currLoss = loss.item()\n",
    "                loss_history.append(currLoss)\n",
    "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, num_batches, currLoss))\n",
    "            perf = (correct/(float(len(x_train))))\n",
    "            print('Train performance at epoch %d is %.4f' % (e, perf))\n",
    "            if (noVal == False):\n",
    "                perf = (correct/(float(len(x_train))))\n",
    "\n",
    "                print('Val performance at epoch %d is %.4f' % (e, perf))\n",
    "            T +=1\n",
    "    return perf, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying out learning rate of  0.004210756309466558\n",
      "Epoch 0, Iteration 0, loss = 12.4801\n",
      "Train performance at epoch 0 is 0.1800\n",
      "Epoch 1, Iteration 0, loss = 36.9484\n",
      "Train performance at epoch 1 is 0.5200\n",
      "Epoch 2, Iteration 0, loss = 11.7361\n",
      "Train performance at epoch 2 is 0.9800\n",
      "Epoch 3, Iteration 0, loss = 11.0770\n",
      "Train performance at epoch 3 is 1.2600\n",
      "Epoch 4, Iteration 0, loss = 14.1539\n",
      "Train performance at epoch 4 is 1.5800\n",
      "Epoch 5, Iteration 0, loss = 3.6146\n",
      "Train performance at epoch 5 is 2.2600\n",
      "Epoch 6, Iteration 0, loss = 9.9977\n",
      "Train performance at epoch 6 is 2.7400\n",
      "Epoch 7, Iteration 0, loss = 8.8908\n",
      "Train performance at epoch 7 is 3.2600\n",
      "Epoch 8, Iteration 0, loss = 6.9032\n",
      "Train performance at epoch 8 is 3.7800\n",
      "Epoch 9, Iteration 0, loss = 1.8420\n",
      "Train performance at epoch 9 is 4.5800\n",
      "Epoch 10, Iteration 0, loss = 2.7128\n",
      "Train performance at epoch 10 is 5.2800\n",
      "Epoch 11, Iteration 0, loss = 4.0147\n",
      "Train performance at epoch 11 is 5.8200\n",
      "Epoch 12, Iteration 0, loss = 1.2400\n",
      "Train performance at epoch 12 is 6.6200\n",
      "Epoch 13, Iteration 0, loss = 0.2879\n",
      "Train performance at epoch 13 is 7.5400\n",
      "Epoch 14, Iteration 0, loss = 0.5598\n",
      "Train performance at epoch 14 is 8.3800\n",
      "Epoch 15, Iteration 0, loss = 0.2082\n",
      "Train performance at epoch 15 is 9.3400\n",
      "Epoch 16, Iteration 0, loss = 0.6501\n",
      "Train performance at epoch 16 is 10.1600\n",
      "Epoch 17, Iteration 0, loss = 0.1632\n",
      "Train performance at epoch 17 is 11.1400\n",
      "Epoch 18, Iteration 0, loss = 0.3628\n",
      "Train performance at epoch 18 is 12.0800\n",
      "Epoch 19, Iteration 0, loss = 0.0385\n",
      "Train performance at epoch 19 is 13.0600\n",
      "Epoch 20, Iteration 0, loss = 0.3949\n",
      "Train performance at epoch 20 is 14.0000\n",
      "Epoch 21, Iteration 0, loss = 0.0026\n",
      "Train performance at epoch 21 is 15.0000\n",
      "Epoch 22, Iteration 0, loss = 0.0032\n",
      "Train performance at epoch 22 is 16.0000\n",
      "Epoch 23, Iteration 0, loss = 0.1290\n",
      "Train performance at epoch 23 is 16.9800\n",
      "Epoch 24, Iteration 0, loss = 0.1095\n",
      "Train performance at epoch 24 is 17.9600\n",
      "Trying out learning rate of  0.0015676911098567448\n",
      "Epoch 0, Iteration 0, loss = 9.7325\n",
      "Train performance at epoch 0 is 0.1400\n",
      "Epoch 1, Iteration 0, loss = 10.0364\n",
      "Train performance at epoch 1 is 0.4600\n",
      "Epoch 2, Iteration 0, loss = 13.2525\n",
      "Train performance at epoch 2 is 0.7400\n",
      "Epoch 3, Iteration 0, loss = 5.2076\n",
      "Train performance at epoch 3 is 1.1800\n",
      "Epoch 4, Iteration 0, loss = 2.1135\n",
      "Train performance at epoch 4 is 1.7800\n",
      "Epoch 5, Iteration 0, loss = 0.7475\n",
      "Train performance at epoch 5 is 2.5200\n",
      "Epoch 6, Iteration 0, loss = 2.6179\n",
      "Train performance at epoch 6 is 3.1000\n",
      "Epoch 7, Iteration 0, loss = 1.1496\n",
      "Train performance at epoch 7 is 3.8600\n",
      "Epoch 8, Iteration 0, loss = 0.4905\n",
      "Train performance at epoch 8 is 4.7400\n",
      "Epoch 9, Iteration 0, loss = 0.3058\n",
      "Train performance at epoch 9 is 5.6000\n",
      "Epoch 10, Iteration 0, loss = 0.4980\n",
      "Train performance at epoch 10 is 6.4800\n",
      "Epoch 11, Iteration 0, loss = 0.1176\n",
      "Train performance at epoch 11 is 7.4400\n",
      "Epoch 12, Iteration 0, loss = 0.0902\n",
      "Train performance at epoch 12 is 8.3800\n",
      "Epoch 13, Iteration 0, loss = 0.0231\n",
      "Train performance at epoch 13 is 9.3800\n",
      "Epoch 14, Iteration 0, loss = 0.0183\n",
      "Train performance at epoch 14 is 10.3800\n",
      "Epoch 15, Iteration 0, loss = 0.0212\n",
      "Train performance at epoch 15 is 11.3800\n",
      "Epoch 16, Iteration 0, loss = 0.0244\n",
      "Train performance at epoch 16 is 12.3800\n",
      "Epoch 17, Iteration 0, loss = 0.0321\n",
      "Train performance at epoch 17 is 13.3800\n",
      "Epoch 18, Iteration 0, loss = 0.0343\n",
      "Train performance at epoch 18 is 14.3800\n",
      "Epoch 19, Iteration 0, loss = 0.0137\n",
      "Train performance at epoch 19 is 15.3800\n",
      "Epoch 20, Iteration 0, loss = 0.0100\n",
      "Train performance at epoch 20 is 16.3800\n",
      "Epoch 21, Iteration 0, loss = 0.0042\n",
      "Train performance at epoch 21 is 17.3800\n",
      "Epoch 22, Iteration 0, loss = 0.0055\n",
      "Train performance at epoch 22 is 18.3800\n",
      "Epoch 23, Iteration 0, loss = 0.0068\n",
      "Train performance at epoch 23 is 19.3800\n",
      "Epoch 24, Iteration 0, loss = 0.0038\n",
      "Train performance at epoch 24 is 20.3800\n",
      "Trying out learning rate of  0.003427625602806395\n",
      "Epoch 0, Iteration 0, loss = 5.3885\n",
      "Train performance at epoch 0 is 0.2000\n",
      "Epoch 1, Iteration 0, loss = 15.0658\n",
      "Train performance at epoch 1 is 0.5800\n",
      "Epoch 2, Iteration 0, loss = 4.2285\n",
      "Train performance at epoch 2 is 1.0800\n",
      "Epoch 3, Iteration 0, loss = 6.8302\n",
      "Train performance at epoch 3 is 1.5000\n",
      "Epoch 4, Iteration 0, loss = 5.1325\n",
      "Train performance at epoch 4 is 2.1000\n",
      "Epoch 5, Iteration 0, loss = 0.4964\n",
      "Train performance at epoch 5 is 2.9000\n",
      "Epoch 6, Iteration 0, loss = 1.3095\n",
      "Train performance at epoch 6 is 3.6800\n",
      "Epoch 7, Iteration 0, loss = 0.9722\n",
      "Train performance at epoch 7 is 4.6000\n",
      "Epoch 8, Iteration 0, loss = 1.7949\n",
      "Train performance at epoch 8 is 5.3800\n",
      "Epoch 9, Iteration 0, loss = 0.6677\n",
      "Train performance at epoch 9 is 6.2400\n",
      "Epoch 10, Iteration 0, loss = 0.2914\n",
      "Train performance at epoch 10 is 7.1400\n",
      "Epoch 11, Iteration 0, loss = 0.0929\n",
      "Train performance at epoch 11 is 8.0800\n",
      "Epoch 12, Iteration 0, loss = 0.0874\n",
      "Train performance at epoch 12 is 9.0600\n",
      "Epoch 13, Iteration 0, loss = 0.0719\n",
      "Train performance at epoch 13 is 10.0400\n",
      "Epoch 14, Iteration 0, loss = 0.2665\n",
      "Train performance at epoch 14 is 11.0000\n",
      "Epoch 15, Iteration 0, loss = 0.1337\n",
      "Train performance at epoch 15 is 11.9600\n",
      "Epoch 16, Iteration 0, loss = 0.0464\n",
      "Train performance at epoch 16 is 12.9600\n",
      "Epoch 17, Iteration 0, loss = 0.0006\n",
      "Train performance at epoch 17 is 13.9600\n",
      "Epoch 18, Iteration 0, loss = 0.0006\n",
      "Train performance at epoch 18 is 14.9600\n",
      "Epoch 19, Iteration 0, loss = 0.0003\n",
      "Train performance at epoch 19 is 15.9600\n",
      "Epoch 20, Iteration 0, loss = 0.0001\n",
      "Train performance at epoch 20 is 16.9600\n",
      "Epoch 21, Iteration 0, loss = 0.0004\n",
      "Train performance at epoch 21 is 17.9600\n",
      "Epoch 22, Iteration 0, loss = 0.0008\n",
      "Train performance at epoch 22 is 18.9600\n",
      "Epoch 23, Iteration 0, loss = 0.0010\n",
      "Train performance at epoch 23 is 19.9600\n",
      "Epoch 24, Iteration 0, loss = 0.0032\n",
      "Train performance at epoch 24 is 20.9600\n",
      "Trying out learning rate of  0.003611953690076415\n",
      "Epoch 0, Iteration 0, loss = 6.4606\n",
      "Train performance at epoch 0 is 0.4200\n",
      "Epoch 1, Iteration 0, loss = 51.0973\n",
      "Train performance at epoch 1 is 0.6600\n",
      "Epoch 2, Iteration 0, loss = 17.7426\n",
      "Train performance at epoch 2 is 0.8400\n",
      "Epoch 3, Iteration 0, loss = 19.5140\n",
      "Train performance at epoch 3 is 1.1400\n",
      "Epoch 4, Iteration 0, loss = 9.8409\n",
      "Train performance at epoch 4 is 1.5800\n",
      "Epoch 5, Iteration 0, loss = 9.1745\n",
      "Train performance at epoch 5 is 1.9400\n",
      "Epoch 6, Iteration 0, loss = 11.4830\n",
      "Train performance at epoch 6 is 2.2800\n",
      "Epoch 7, Iteration 0, loss = 6.4434\n",
      "Train performance at epoch 7 is 2.7800\n",
      "Epoch 8, Iteration 0, loss = 2.3985\n",
      "Train performance at epoch 8 is 3.4400\n",
      "Epoch 9, Iteration 0, loss = 0.7602\n",
      "Train performance at epoch 9 is 4.1800\n",
      "Epoch 10, Iteration 0, loss = 0.7906\n",
      "Train performance at epoch 10 is 4.9600\n",
      "Epoch 11, Iteration 0, loss = 1.9441\n",
      "Train performance at epoch 11 is 5.6600\n",
      "Epoch 12, Iteration 0, loss = 1.9068\n",
      "Train performance at epoch 12 is 6.3000\n",
      "Epoch 13, Iteration 0, loss = 0.7964\n",
      "Train performance at epoch 13 is 7.1000\n",
      "Epoch 14, Iteration 0, loss = 0.4766\n",
      "Train performance at epoch 14 is 7.9800\n",
      "Epoch 15, Iteration 0, loss = 0.3387\n",
      "Train performance at epoch 15 is 8.8400\n",
      "Epoch 16, Iteration 0, loss = 0.5075\n",
      "Train performance at epoch 16 is 9.7200\n",
      "Epoch 17, Iteration 0, loss = 0.4307\n",
      "Train performance at epoch 17 is 10.5200\n",
      "Epoch 18, Iteration 0, loss = 0.1547\n",
      "Train performance at epoch 18 is 11.4600\n",
      "Epoch 19, Iteration 0, loss = 0.0956\n",
      "Train performance at epoch 19 is 12.4400\n",
      "Epoch 20, Iteration 0, loss = 0.1011\n",
      "Train performance at epoch 20 is 13.3800\n",
      "Epoch 21, Iteration 0, loss = 0.0196\n",
      "Train performance at epoch 21 is 14.3800\n",
      "Epoch 22, Iteration 0, loss = 0.0012\n",
      "Train performance at epoch 22 is 15.3800\n",
      "Epoch 23, Iteration 0, loss = 0.0198\n",
      "Train performance at epoch 23 is 16.3800\n",
      "Epoch 24, Iteration 0, loss = 0.0067\n",
      "Train performance at epoch 24 is 17.3800\n",
      "Trying out learning rate of  0.002147418314081924\n",
      "Epoch 0, Iteration 0, loss = 6.1570\n",
      "Train performance at epoch 0 is 0.0800\n",
      "Epoch 1, Iteration 0, loss = 8.2841\n",
      "Train performance at epoch 1 is 0.3800\n",
      "Epoch 2, Iteration 0, loss = 2.8917\n",
      "Train performance at epoch 2 is 0.9200\n",
      "Epoch 3, Iteration 0, loss = 1.0398\n",
      "Train performance at epoch 3 is 1.6000\n",
      "Epoch 4, Iteration 0, loss = 1.7167\n",
      "Train performance at epoch 4 is 2.3400\n",
      "Epoch 5, Iteration 0, loss = 0.7664\n",
      "Train performance at epoch 5 is 3.1400\n",
      "Epoch 6, Iteration 0, loss = 0.2339\n",
      "Train performance at epoch 6 is 4.0800\n",
      "Epoch 7, Iteration 0, loss = 0.0737\n",
      "Train performance at epoch 7 is 5.0400\n",
      "Epoch 8, Iteration 0, loss = 0.4920\n",
      "Train performance at epoch 8 is 5.8800\n",
      "Epoch 9, Iteration 0, loss = 0.4519\n",
      "Train performance at epoch 9 is 6.8000\n",
      "Epoch 10, Iteration 0, loss = 0.0324\n",
      "Train performance at epoch 10 is 7.7800\n",
      "Epoch 11, Iteration 0, loss = 0.0263\n",
      "Train performance at epoch 11 is 8.7600\n",
      "Epoch 12, Iteration 0, loss = 0.1740\n",
      "Train performance at epoch 12 is 9.7400\n",
      "Epoch 13, Iteration 0, loss = 0.1558\n",
      "Train performance at epoch 13 is 10.7200\n",
      "Epoch 14, Iteration 0, loss = 0.2771\n",
      "Train performance at epoch 14 is 11.6600\n",
      "Epoch 15, Iteration 0, loss = 0.2816\n",
      "Train performance at epoch 15 is 12.5600\n",
      "Epoch 16, Iteration 0, loss = 0.0024\n",
      "Train performance at epoch 16 is 13.5600\n",
      "Epoch 17, Iteration 0, loss = 0.0220\n",
      "Train performance at epoch 17 is 14.5600\n",
      "Epoch 18, Iteration 0, loss = 0.1704\n",
      "Train performance at epoch 18 is 15.5400\n",
      "Epoch 19, Iteration 0, loss = 0.0279\n",
      "Train performance at epoch 19 is 16.5200\n",
      "Epoch 20, Iteration 0, loss = 0.0049\n",
      "Train performance at epoch 20 is 17.5200\n",
      "Epoch 21, Iteration 0, loss = 0.0244\n",
      "Train performance at epoch 21 is 18.5200\n",
      "Epoch 22, Iteration 0, loss = 0.0168\n",
      "Train performance at epoch 22 is 19.5200\n",
      "Epoch 23, Iteration 0, loss = 0.0040\n",
      "Train performance at epoch 23 is 20.5200\n",
      "Epoch 24, Iteration 0, loss = 0.0034\n",
      "Train performance at epoch 24 is 21.5200\n"
     ]
    }
   ],
   "source": [
    "# Overfitting data first\n",
    "bestPerf = -1\n",
    "lossHistory = None\n",
    "lossHistories = {}\n",
    "print_every = 1\n",
    "bestModel = None\n",
    "bestLoss = 10000\n",
    "lrUsed = 0\n",
    "x_train = X_train[0:50, :, :, :]\n",
    "y_train = Y_train[0:50]\n",
    "lrs = []\n",
    "for i in range(4):\n",
    "    lrs.append(5*np.random.rand()*1e-3)\n",
    "# lrs = [1e-7,1e-6,1e-5,1e-4,1e-3]\n",
    "lrs.append(.002147418314081924) # Best result from last random searches\n",
    "for lr in lrs:\n",
    "    print('Trying out learning rate of ', lr)\n",
    "    model = NNet()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "    modelPerf = trainModel(model, x_train, y_train, optimizer, epochs = 25, noVal = True)\n",
    "    lossHistories[str(lr)] = modelPerf[1]\n",
    "    if modelPerf[1][len(modelPerf[1])-1] < bestLoss:\n",
    "        bestLoss = modelPerf[1][len(modelPerf[1])-1]\n",
    "        bestPerf = modelPerf[0]\n",
    "        lossHistory = modelPerf[1]\n",
    "        bestModel = model\n",
    "        lrUsed = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
